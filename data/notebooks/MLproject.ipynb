{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaCTi2WyxId6",
        "outputId": "9fd9bc57-c0f2-42d1-e3ec-7fa4b1ea1b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1025119734.py:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['sentiment'] = df['sentiment'].replace({'positive': 1, 'negative': 0})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model A: Logistic Regression Final Results ---\n",
            "Accuracy    0.8879\n",
            "F1-Score    0.8863\n",
            "AUC-ROC     0.9528\n",
            "Time        0.2069\n",
            "dtype: float64\n",
            "\n",
            "Classification Report (LR):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       868\n",
            "           1       0.89      0.89      0.89       845\n",
            "\n",
            "    accuracy                           0.89      1713\n",
            "   macro avg       0.89      0.89      0.89      1713\n",
            "weighted avg       0.89      0.89      0.89      1713\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 554ms/step - accuracy: 0.5106 - loss: 0.6935 - val_accuracy: 0.4944 - val_loss: 0.6931\n",
            "Epoch 2/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 586ms/step - accuracy: 0.5125 - loss: 0.6920 - val_accuracy: 0.5155 - val_loss: 0.6914\n",
            "Epoch 3/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 562ms/step - accuracy: 0.5423 - loss: 0.6739 - val_accuracy: 0.5015 - val_loss: 0.6931\n",
            "Epoch 4/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 574ms/step - accuracy: 0.5473 - loss: 0.6440 - val_accuracy: 0.5155 - val_loss: 0.7115\n",
            "Epoch 5/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 571ms/step - accuracy: 0.5458 - loss: 0.6368 - val_accuracy: 0.5056 - val_loss: 0.7372\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "--- Model B: LSTM Final Results ---\n",
            "Accuracy      0.5108\n",
            "F1-Score      0.1396\n",
            "AUC-ROC       0.5030\n",
            "Time        615.1619\n",
            "dtype: float64\n",
            "\n",
            "Classification Report (LSTM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.93      0.66       868\n",
            "           1       0.53      0.08      0.14       845\n",
            "\n",
            "    accuracy                           0.51      1713\n",
            "   macro avg       0.52      0.51      0.40      1713\n",
            "weighted avg       0.52      0.51      0.40      1713\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
        "import time\n",
        "import requests\n",
        "from io import StringIO\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "DATA_URL = 'https://raw.githubusercontent.com/AnshulBhusari/IMDB_Sentiment_Analysis_Project/main/IMDB%20Dataset.csv'\n",
        "\n",
        "try:\n",
        "    response = requests.get(DATA_URL)\n",
        "    response.raise_for_status()\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    raise Exception(f\"Critical: Could not load the IMDb dataset. Error: {e}\")\n",
        "\n",
        "df['sentiment'] = df['sentiment'].replace({'positive': 1, 'negative': 0})\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    df['review'], df['sentiment'], test_size=0.1, random_state=42, stratify=df['sentiment']\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.111, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOP_WORDS)\n",
        "    return text\n",
        "\n",
        "X_train_cleaned = X_train.apply(clean_text)\n",
        "X_val_cleaned = X_val.apply(clean_text)\n",
        "X_test_cleaned = X_test.apply(clean_text)\n",
        "\n",
        "# --- MODEL A: LOGISTIC REGRESSION ---\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_cleaned)\n",
        "X_test_tfidf = vectorizer.transform(X_test_cleaned)\n",
        "\n",
        "lr = LogisticRegression(solver='liblinear', C=1.0, random_state=42)\n",
        "start_time_lr = time.time()\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "end_time_lr = time.time()\n",
        "\n",
        "y_pred_lr = lr.predict(X_test_tfidf)\n",
        "y_proba_lr = lr.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "results_lr = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_lr),\n",
        "    'F1-Score': f1_score(y_test, y_pred_lr),\n",
        "    'AUC-ROC': roc_auc_score(y_test, y_proba_lr),\n",
        "    'Time': end_time_lr - start_time_lr\n",
        "}\n",
        "print(\"\\n--- Model A: Logistic Regression Final Results ---\")\n",
        "print(pd.Series(results_lr).round(4))\n",
        "print(\"\\nClassification Report (LR):\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# --- MODEL B: LSTM ---\n",
        "MAX_WORDS = 10000\n",
        "MAX_LEN = 256\n",
        "EMBEDDING_DIM = 128\n",
        "LSTM_UNITS = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_cleaned.astype(str))\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train_cleaned)\n",
        "val_sequences = tokenizer.texts_to_sequences(X_val_cleaned)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test_cleaned)\n",
        "\n",
        "X_train_seq = pad_sequences(train_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "X_val_seq = pad_sequences(val_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "X_test_seq = pad_sequences(test_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=MAX_LEN, name='embedding_layer'),\n",
        "    Dropout(0.3, name='dropout_1'),\n",
        "    LSTM(LSTM_UNITS, name='lstm_layer'),\n",
        "    Dropout(0.3, name='dropout_2'),\n",
        "    Dense(1, activation='sigmoid', name='output_layer')\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_lstm_model.keras', monitor='val_loss', save_best_only=True, verbose=0)\n",
        "]\n",
        "\n",
        "start_time_lstm = time.time()\n",
        "history = lstm_model.fit(\n",
        "    X_train_seq, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "end_time_lstm = time.time()\n",
        "training_time_lstm = end_time_lstm - start_time_lstm\n",
        "\n",
        "lstm_model.load_weights('best_lstm_model.keras')\n",
        "y_pred_proba_lstm = lstm_model.predict(X_test_seq, verbose=0)\n",
        "y_pred_lstm = (y_pred_proba_lstm > 0.5).astype(int)\n",
        "\n",
        "results_lstm = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_lstm),\n",
        "    'F1-Score': f1_score(y_test, y_pred_lstm),\n",
        "    'AUC-ROC': roc_auc_score(y_test, y_pred_proba_lstm),\n",
        "    'Time': training_time_lstm\n",
        "}\n",
        "\n",
        "print(\"\\n--- Model B: LSTM Final Results ---\")\n",
        "print(pd.Series(results_lstm).round(4))\n",
        "print(\"\\nClassification Report (LSTM):\")\n",
        "print(classification_report(y_test, y_pred_lstm))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mys6SZARx1T5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}